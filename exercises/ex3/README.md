## Exercise 3 (Multi Layer Perceptron)

Goal of this exercise is to extend the MNIST logistic classifier to an MLP network with hidden layers (784-225-144-10). 
Tasks
-----
1. Compare basic *gradient descent* with *mini-batch* training using 100 examples per mini-batch and momentum. The training samples were to be shuffled. 
2. Plot training error as a function of training time. Test and Validation error were not evaluated in this exercise.
3. To Study the effect of scale of initialization by using the proposed [Xavier10] scale compared to 10 times larger or smaller scale.

References
----------
[Xavier10]	Bengio, X. Glorot, Understanding the difficulty of training deep feedforward neuralnetworks, AISTATS 2010
